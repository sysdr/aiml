#!/bin/bash

# Day 73: Pipelines - Chaining Steps Together
# This script generates all necessary files for the lesson

echo "Generating Day 73 lesson files..."

# Create requirements.txt
cat > requirements.txt << 'EOF'
numpy==1.26.4
pandas==2.2.1
scikit-learn==1.4.1.post1
matplotlib==3.8.3
seaborn==0.13.2
joblib==1.3.2
pytest==8.1.1
pytest-cov==4.1.0
EOF

# Create lesson_code.py
cat > lesson_code.py << 'EOF'
"""
Day 73: Pipelines - Chaining Steps Together
Production-grade ML workflow automation
"""

import numpy as np
import pandas as pd
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
import joblib
import warnings
warnings.filterwarnings('ignore')


def demonstrate_basic_pipeline():
    """
    Basic pipeline: scaler + classifier
    Shows fundamental pipeline construction and usage
    """
    print("=" * 60)
    print("PART 1: Basic Pipeline Construction")
    print("=" * 60)
    
    # Generate synthetic classification dataset
    X, y = make_classification(
        n_samples=1000,
        n_features=20,
        n_informative=15,
        n_redundant=5,
        random_state=42
    )
    
    # Split data BEFORE any preprocessing
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    print(f"\nDataset shape: {X.shape}")
    print(f"Training samples: {X_train.shape[0]}")
    print(f"Test samples: {X_test.shape[0]}")
    
    # Create pipeline
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', LogisticRegression(random_state=42, max_iter=1000))
    ])
    
    print("\nPipeline structure:")
    for name, step in pipeline.steps:
        print(f"  {name}: {step.__class__.__name__}")
    
    # Train pipeline (fits scaler on train data, then classifier)
    print("\nTraining pipeline...")
    pipeline.fit(X_train, y_train)
    
    # Evaluate
    train_score = pipeline.score(X_train, y_train)
    test_score = pipeline.score(X_test, y_test)
    
    print(f"\nResults:")
    print(f"  Training accuracy: {train_score:.4f}")
    print(f"  Test accuracy: {test_score:.4f}")
    print(f"  Generalization gap: {train_score - test_score:.4f}")
    
    return pipeline


def demonstrate_data_leakage_prevention():
    """
    Compare proper pipeline usage vs data leakage scenario
    Shows why pipelines matter for correct evaluation
    """
    print("\n" + "=" * 60)
    print("PART 2: Data Leakage Prevention")
    print("=" * 60)
    
    # Generate dataset
    X, y = make_classification(
        n_samples=1000,
        n_features=20,
        n_informative=10,
        random_state=42
    )
    
    # WRONG WAY: Scale before split (data leakage)
    print("\nâŒ WRONG: Scaling before train/test split")
    scaler_wrong = StandardScaler()
    X_scaled_wrong = scaler_wrong.fit_transform(X)  # Sees ALL data
    X_train_wrong, X_test_wrong, y_train_wrong, y_test_wrong = train_test_split(
        X_scaled_wrong, y, test_size=0.2, random_state=42
    )
    
    clf_wrong = LogisticRegression(random_state=42, max_iter=1000)
    clf_wrong.fit(X_train_wrong, y_train_wrong)
    wrong_score = clf_wrong.score(X_test_wrong, y_test_wrong)
    print(f"  Test accuracy (with leakage): {wrong_score:.4f}")
    
    # RIGHT WAY: Pipeline prevents leakage
    print("\nâœ… CORRECT: Pipeline with proper isolation")
    X_train_right, X_test_right, y_train_right, y_test_right = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    pipeline_right = Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', LogisticRegression(random_state=42, max_iter=1000))
    ])
    pipeline_right.fit(X_train_right, y_train_right)  # Scaler fits only on train
    right_score = pipeline_right.score(X_test_right, y_test_right)
    print(f"  Test accuracy (no leakage): {right_score:.4f}")
    
    # Show the difference
    difference = wrong_score - right_score
    print(f"\nðŸ“Š Performance difference: {difference:.4f}")
    print(f"   Leaked model appears {difference*100:.2f}% better (falsely optimistic)")
    
    return pipeline_right


def demonstrate_column_transformer():
    """
    ColumnTransformer for heterogeneous data
    Production pattern for real-world datasets with mixed types
    """
    print("\n" + "=" * 60)
    print("PART 3: ColumnTransformer for Mixed Data Types")
    print("=" * 60)
    
    # Create realistic dataset with numerical and categorical features
    np.random.seed(42)
    n_samples = 1000
    
    data = pd.DataFrame({
        'age': np.random.randint(18, 80, n_samples),
        'income': np.random.normal(50000, 20000, n_samples),
        'credit_score': np.random.randint(300, 850, n_samples),
        'city': np.random.choice(['NYC', 'LA', 'Chicago', 'Houston'], n_samples),
        'employment': np.random.choice(['Full-time', 'Part-time', 'Self-employed'], n_samples),
        'owns_home': np.random.choice(['Yes', 'No'], n_samples)
    })
    
    # Add some missing values (realistic scenario)
    data.loc[np.random.choice(data.index, 50), 'income'] = np.nan
    data.loc[np.random.choice(data.index, 30), 'age'] = np.nan
    
    # Target variable (loan approval)
    y = (data['credit_score'] > 650).astype(int)
    
    print(f"\nDataset shape: {data.shape}")
    print(f"\nFeature types:")
    print(data.dtypes)
    print(f"\nMissing values:")
    print(data.isnull().sum())
    
    # Define column types
    numerical_features = ['age', 'income', 'credit_score']
    categorical_features = ['city', 'employment', 'owns_home']
    
    # Create preprocessing pipelines for each type
    numerical_pipeline = Pipeline([
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ])
    
    categorical_pipeline = Pipeline([
        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
    ])
    
    # Combine into ColumnTransformer
    preprocessor = ColumnTransformer([
        ('num', numerical_pipeline, numerical_features),
        ('cat', categorical_pipeline, categorical_features)
    ])
    
    # Full pipeline with classifier
    full_pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
    ])
    
    print("\nðŸ“‹ Pipeline structure:")
    print("  1. Numerical pipeline:")
    print("     - Impute missing values (median)")
    print("     - Scale features (standardization)")
    print("  2. Categorical pipeline:")
    print("     - Impute missing values (constant)")
    print("     - One-hot encode categories")
    print("  3. Random Forest classifier")
    
    # Split and train
    X_train, X_test, y_train, y_test = train_test_split(
        data, y, test_size=0.2, random_state=42
    )
    
    print("\nTraining full pipeline...")
    full_pipeline.fit(X_train, y_train)
    
    # Evaluate
    train_score = full_pipeline.score(X_train, y_train)
    test_score = full_pipeline.score(X_test, y_test)
    
    print(f"\nResults:")
    print(f"  Training accuracy: {train_score:.4f}")
    print(f"  Test accuracy: {test_score:.4f}")
    
    # Show transformed feature count
    X_transformed = preprocessor.fit_transform(X_train)
    print(f"\nðŸ”„ Feature transformation:")
    print(f"  Original features: {data.shape[1]}")
    print(f"  Transformed features: {X_transformed.shape[1]}")
    print(f"  (One-hot encoding expanded categorical features)")
    
    return full_pipeline


def demonstrate_cross_validation_with_pipeline():
    """
    Cross-validation with pipelines
    Proper CV ensures no data leakage across folds
    """
    print("\n" + "=" * 60)
    print("PART 4: Cross-Validation with Pipelines")
    print("=" * 60)
    
    # Generate dataset
    X, y = make_classification(
        n_samples=1000,
        n_features=20,
        n_informative=15,
        random_state=42
    )
    
    # Create pipeline
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', LogisticRegression(random_state=42, max_iter=1000))
    ])
    
    print("\nRunning 5-fold cross-validation...")
    print("(Each fold: fit scaler on train folds, transform test fold)")
    
    # Perform cross-validation
    cv_scores = cross_val_score(
        pipeline, X, y, 
        cv=5, 
        scoring='accuracy'
    )
    
    print(f"\nCross-validation scores:")
    for i, score in enumerate(cv_scores, 1):
        print(f"  Fold {i}: {score:.4f}")
    
    print(f"\nMean CV accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
    
    return pipeline, cv_scores


def demonstrate_serialization():
    """
    Pipeline serialization for production deployment
    Save trained pipeline, load later for inference
    """
    print("\n" + "=" * 60)
    print("PART 5: Pipeline Serialization")
    print("=" * 60)
    
    # Train a pipeline
    X, y = make_classification(n_samples=1000, n_features=20, random_state=42)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', LogisticRegression(random_state=42, max_iter=1000))
    ])
    
    pipeline.fit(X_train, y_train)
    original_predictions = pipeline.predict(X_test)
    original_score = pipeline.score(X_test, y_test)
    
    # Save pipeline
    model_filename = 'pipeline_model.pkl'
    print(f"\nðŸ’¾ Saving pipeline to {model_filename}...")
    joblib.dump(pipeline, model_filename)
    
    # Load pipeline
    print(f"ðŸ“‚ Loading pipeline from {model_filename}...")
    loaded_pipeline = joblib.load(model_filename)
    
    # Verify loaded pipeline produces identical results
    loaded_predictions = loaded_pipeline.predict(X_test)
    loaded_score = loaded_pipeline.score(X_test, y_test)
    
    print(f"\nâœ… Verification:")
    print(f"  Original accuracy: {original_score:.4f}")
    print(f"  Loaded accuracy: {loaded_score:.4f}")
    print(f"  Predictions match: {np.array_equal(original_predictions, loaded_predictions)}")
    
    return loaded_pipeline


def production_pipeline_example():
    """
    Complete production-ready pipeline example
    Demonstrates best practices used in real ML systems
    """
    print("\n" + "=" * 60)
    print("PART 6: Production Pipeline Pattern")
    print("=" * 60)
    
    # Create realistic customer churn dataset
    np.random.seed(42)
    n_samples = 2000
    
    data = pd.DataFrame({
        'account_age_months': np.random.randint(1, 120, n_samples),
        'monthly_usage_gb': np.random.lognormal(3, 1, n_samples),
        'support_tickets': np.random.poisson(2, n_samples),
        'subscription_price': np.random.choice([9.99, 14.99, 19.99, 29.99], n_samples),
        'plan_type': np.random.choice(['Basic', 'Pro', 'Enterprise'], n_samples),
        'device_type': np.random.choice(['Mobile', 'Desktop', 'Tablet'], n_samples),
        'payment_method': np.random.choice(['Credit Card', 'PayPal', 'Bank Transfer'], n_samples)
    })
    
    # Target: customer churn
    churn_probability = (
        (data['account_age_months'] < 12) * 0.3 +
        (data['support_tickets'] > 3) * 0.2 +
        (data['monthly_usage_gb'] < 5) * 0.2 +
        np.random.random(n_samples) * 0.3
    )
    y = (churn_probability > 0.5).astype(int)
    
    print(f"\nðŸ“Š Customer Churn Dataset")
    print(f"  Total customers: {n_samples}")
    print(f"  Churn rate: {y.mean()*100:.1f}%")
    print(f"  Features: {data.shape[1]}")
    
    # Define feature groups
    numerical_features = ['account_age_months', 'monthly_usage_gb', 'support_tickets', 'subscription_price']
    categorical_features = ['plan_type', 'device_type', 'payment_method']
    
    # Build production pipeline
    numerical_transformer = Pipeline([
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ])
    
    categorical_transformer = Pipeline([
        ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),
        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
    ])
    
    preprocessor = ColumnTransformer([
        ('num', numerical_transformer, numerical_features),
        ('cat', categorical_transformer, categorical_features)
    ])
    
    # Full pipeline with optimized classifier
    production_pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            min_samples_split=20,
            random_state=42
        ))
    ])
    
    # Train/test split
    X_train, X_test, y_train, y_test = train_test_split(
        data, y, test_size=0.2, stratify=y, random_state=42
    )
    
    print("\nðŸ”§ Training production pipeline...")
    production_pipeline.fit(X_train, y_train)
    
    # Evaluate
    train_score = production_pipeline.score(X_train, y_train)
    test_score = production_pipeline.score(X_test, y_test)
    
    print(f"\nðŸ“ˆ Performance Metrics:")
    print(f"  Training accuracy: {train_score:.4f}")
    print(f"  Test accuracy: {test_score:.4f}")
    print(f"  Generalization: {(test_score/train_score)*100:.1f}%")
    
    # Cross-validation for robust estimate
    cv_scores = cross_val_score(
        production_pipeline, data, y, cv=5, scoring='accuracy'
    )
    print(f"\n  5-fold CV accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})")
    
    # Save for deployment
    print("\nðŸ’¾ Saving production model...")
    joblib.dump(production_pipeline, 'churn_model_v1.pkl')
    print("  âœ… Model saved: churn_model_v1.pkl")
    print("  Ready for deployment!")
    
    return production_pipeline


def main():
    """Run all pipeline demonstrations"""
    print("\n" + "ðŸš€" * 30)
    print("Day 73: Scikit-learn Pipelines")
    print("Production ML Workflow Automation")
    print("ðŸš€" * 30)
    
    # Run demonstrations
    pipeline1 = demonstrate_basic_pipeline()
    pipeline2 = demonstrate_data_leakage_prevention()
    pipeline3 = demonstrate_column_transformer()
    pipeline4, cv_scores = demonstrate_cross_validation_with_pipeline()
    pipeline5 = demonstrate_serialization()
    pipeline6 = production_pipeline_example()
    
    print("\n" + "=" * 60)
    print("âœ… All demonstrations complete!")
    print("=" * 60)
    print("\nKey Takeaways:")
    print("1. Pipelines prevent data leakage by fitting transformers only on training data")
    print("2. ColumnTransformer handles mixed data types elegantly")
    print("3. Cross-validation with pipelines ensures proper fold isolation")
    print("4. Serialization makes deployment reproducible")
    print("5. Production pipelines chain preprocessing and models into single objects")
    print("\nðŸ’¡ Next: Feature Engineering (Day 74)")


if __name__ == "__main__":
    main()
EOF

# Create test_lesson.py
cat > test_lesson.py << 'EOF'
"""
Test suite for Day 73: Pipelines
Comprehensive tests for pipeline functionality
"""

import pytest
import numpy as np
import pandas as pd
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.datasets import make_classification
import joblib
import os


class TestBasicPipeline:
    """Test basic pipeline construction and usage"""
    
    def test_pipeline_creation(self):
        """Test pipeline can be created with multiple steps"""
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('classifier', LogisticRegression())
        ])
        assert len(pipeline.steps) == 2
        assert pipeline.named_steps['scaler'].__class__.__name__ == 'StandardScaler'
        assert pipeline.named_steps['classifier'].__class__.__name__ == 'LogisticRegression'
    
    def test_pipeline_fit_predict(self):
        """Test pipeline can fit and predict"""
        X, y = make_classification(n_samples=100, n_features=10, random_state=42)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('classifier', LogisticRegression(random_state=42))
        ])
        
        pipeline.fit(X_train, y_train)
        predictions = pipeline.predict(X_test)
        
        assert predictions.shape[0] == X_test.shape[0]
        assert set(predictions).issubset({0, 1})
    
    def test_pipeline_score(self):
        """Test pipeline scoring works correctly"""
        X, y = make_classification(n_samples=100, n_features=10, random_state=42)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('classifier', LogisticRegression(random_state=42))
        ])
        
        pipeline.fit(X_train, y_train)
        score = pipeline.score(X_test, y_test)
        
        assert 0 <= score <= 1


class TestDataLeakagePrevention:
    """Test that pipelines prevent data leakage"""
    
    def test_scaler_fits_only_on_train(self):
        """Verify scaler statistics computed only from training data"""
        X, y = make_classification(n_samples=200, n_features=5, random_state=42)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)
        
        # Fit pipeline on train data only
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('classifier', LogisticRegression(random_state=42))
        ])
        pipeline.fit(X_train, y_train)
        
        # Get scaler statistics
        scaler_mean = pipeline.named_steps['scaler'].mean_
        
        # Compute train data mean manually
        train_mean = X_train.mean(axis=0)
        
        # Should match train data statistics, not full dataset
        np.testing.assert_array_almost_equal(scaler_mean, train_mean, decimal=5)
    
    def test_proper_isolation_better_than_leakage(self):
        """Test that proper pipeline isolation gives realistic performance"""
        X, y = make_classification(n_samples=500, n_features=20, random_state=42)
        
        # Method 1: WRONG - scale before split
        scaler_wrong = StandardScaler()
        X_scaled_wrong = scaler_wrong.fit_transform(X)
        X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(
            X_scaled_wrong, y, test_size=0.2, random_state=42
        )
        clf_wrong = LogisticRegression(random_state=42)
        clf_wrong.fit(X_train_w, y_train_w)
        score_wrong = clf_wrong.score(X_test_w, y_test_w)
        
        # Method 2: CORRECT - pipeline prevents leakage
        X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        pipeline_right = Pipeline([
            ('scaler', StandardScaler()),
            ('classifier', LogisticRegression(random_state=42))
        ])
        pipeline_right.fit(X_train_r, y_train_r)
        score_right = pipeline_right.score(X_test_r, y_test_r)
        
        # Leaked version usually has artificially high score
        assert score_wrong >= score_right - 0.05  # Allow small variance


class TestColumnTransformer:
    """Test ColumnTransformer for heterogeneous data"""
    
    def test_column_transformer_creation(self):
        """Test ColumnTransformer handles different feature types"""
        numerical_features = ['num1', 'num2']
        categorical_features = ['cat1', 'cat2']
        
        preprocessor = ColumnTransformer([
            ('num', StandardScaler(), numerical_features),
            ('cat', OneHotEncoder(), categorical_features)
        ])
        
        assert len(preprocessor.transformers) == 2
    
    def test_mixed_type_pipeline(self):
        """Test pipeline with mixed numerical and categorical features"""
        # Create mixed-type dataset
        data = pd.DataFrame({
            'num1': np.random.randn(100),
            'num2': np.random.randn(100),
            'cat1': np.random.choice(['A', 'B', 'C'], 100),
            'cat2': np.random.choice(['X', 'Y'], 100)
        })
        y = np.random.randint(0, 2, 100)
        
        numerical_features = ['num1', 'num2']
        categorical_features = ['cat1', 'cat2']
        
        preprocessor = ColumnTransformer([
            ('num', StandardScaler(), numerical_features),
            ('cat', OneHotEncoder(sparse_output=False), categorical_features)
        ])
        
        pipeline = Pipeline([
            ('preprocessor', preprocessor),
            ('classifier', LogisticRegression(random_state=42))
        ])
        
        X_train, X_test, y_train, y_test = train_test_split(
            data, y, test_size=0.2, random_state=42
        )
        
        pipeline.fit(X_train, y_train)
        predictions = pipeline.predict(X_test)
        
        assert predictions.shape[0] == X_test.shape[0]
    
    def test_missing_value_handling(self):
        """Test pipeline handles missing values correctly"""
        data = pd.DataFrame({
            'num1': [1, 2, np.nan, 4, 5],
            'cat1': ['A', 'B', None, 'A', 'B']
        })
        y = np.array([0, 1, 0, 1, 0])
        
        preprocessor = ColumnTransformer([
            ('num', Pipeline([
                ('imputer', SimpleImputer(strategy='mean')),
                ('scaler', StandardScaler())
            ]), ['num1']),
            ('cat', Pipeline([
                ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
                ('onehot', OneHotEncoder(sparse_output=False))
            ]), ['cat1'])
        ])
        
        pipeline = Pipeline([
            ('preprocessor', preprocessor),
            ('classifier', LogisticRegression(random_state=42))
        ])
        
        pipeline.fit(data, y)
        predictions = pipeline.predict(data)
        
        assert not np.isnan(predictions).any()


class TestCrossValidation:
    """Test cross-validation with pipelines"""
    
    def test_cv_with_pipeline(self):
        """Test cross-validation properly uses pipeline"""
        X, y = make_classification(n_samples=200, n_features=10, random_state=42)
        
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('classifier', LogisticRegression(random_state=42))
        ])
        
        cv_scores = cross_val_score(pipeline, X, y, cv=5)
        
        assert len(cv_scores) == 5
        assert all(0 <= score <= 1 for score in cv_scores)
    
    def test_cv_prevents_leakage(self):
        """Verify CV fits scaler separately for each fold"""
        X, y = make_classification(n_samples=150, n_features=10, random_state=42)
        
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('classifier', LogisticRegression(random_state=42))
        ])
        
        # CV should work without errors
        cv_scores = cross_val_score(pipeline, X, y, cv=3)
        
        assert len(cv_scores) == 3
        # CV scores should be reasonable (not perfect)
        assert all(0.4 <= score <= 1.0 for score in cv_scores)


class TestSerialization:
    """Test pipeline serialization and deserialization"""
    
    def test_save_load_pipeline(self):
        """Test pipeline can be saved and loaded"""
        X, y = make_classification(n_samples=100, n_features=10, random_state=42)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('classifier', LogisticRegression(random_state=42))
        ])
        
        pipeline.fit(X_train, y_train)
        original_predictions = pipeline.predict(X_test)
        
        # Save pipeline
        filename = 'test_pipeline.pkl'
        joblib.dump(pipeline, filename)
        
        # Load pipeline
        loaded_pipeline = joblib.load(filename)
        loaded_predictions = loaded_pipeline.predict(X_test)
        
        # Clean up
        os.remove(filename)
        
        # Predictions should be identical
        np.testing.assert_array_equal(original_predictions, loaded_predictions)
    
    def test_loaded_pipeline_reproducibility(self):
        """Test loaded pipeline produces consistent results"""
        X, y = make_classification(n_samples=100, n_features=10, random_state=42)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('classifier', LogisticRegression(random_state=42))
        ])
        
        pipeline.fit(X_train, y_train)
        original_score = pipeline.score(X_test, y_test)
        
        # Save and load
        filename = 'test_pipeline_2.pkl'
        joblib.dump(pipeline, filename)
        loaded_pipeline = joblib.load(filename)
        loaded_score = loaded_pipeline.score(X_test, y_test)
        
        # Clean up
        os.remove(filename)
        
        # Scores should be identical
        assert original_score == loaded_score


class TestProductionPatterns:
    """Test production-ready pipeline patterns"""
    
    def test_end_to_end_pipeline(self):
        """Test complete preprocessing + training pipeline"""
        data = pd.DataFrame({
            'num1': np.random.randn(100),
            'num2': np.random.randn(100),
            'cat1': np.random.choice(['A', 'B', 'C'], 100),
            'cat2': np.random.choice(['X', 'Y', 'Z'], 100)
        })
        y = np.random.randint(0, 2, 100)
        
        numerical_features = ['num1', 'num2']
        categorical_features = ['cat1', 'cat2']
        
        preprocessor = ColumnTransformer([
            ('num', Pipeline([
                ('imputer', SimpleImputer(strategy='mean')),
                ('scaler', StandardScaler())
            ]), numerical_features),
            ('cat', Pipeline([
                ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
                ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
            ]), categorical_features)
        ])
        
        pipeline = Pipeline([
            ('preprocessor', preprocessor),
            ('classifier', RandomForestClassifier(n_estimators=10, random_state=42))
        ])
        
        X_train, X_test, y_train, y_test = train_test_split(
            data, y, test_size=0.2, random_state=42
        )
        
        pipeline.fit(X_train, y_train)
        score = pipeline.score(X_test, y_test)
        
        assert 0 <= score <= 1
    
    def test_pipeline_with_unknown_categories(self):
        """Test pipeline handles unknown categories in test data"""
        train_data = pd.DataFrame({
            'num': np.random.randn(100),
            'cat': np.random.choice(['A', 'B'], 100)
        })
        test_data = pd.DataFrame({
            'num': np.random.randn(20),
            'cat': np.random.choice(['A', 'B', 'C'], 20)  # 'C' is new
        })
        y_train = np.random.randint(0, 2, 100)
        
        preprocessor = ColumnTransformer([
            ('num', StandardScaler(), ['num']),
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), ['cat'])
        ])
        
        pipeline = Pipeline([
            ('preprocessor', preprocessor),
            ('classifier', LogisticRegression(random_state=42))
        ])
        
        pipeline.fit(train_data, y_train)
        predictions = pipeline.predict(test_data)  # Should not error
        
        assert predictions.shape[0] == test_data.shape[0]


if __name__ == "__main__":
    pytest.main([__file__, '-v', '--tb=short'])
EOF

# Create README.md
cat > README.md << 'EOF'
# Day 73: Pipelines - Chaining Steps Together

## Overview
Learn to build production-grade ML pipelines that chain preprocessing and model training into reproducible workflows. This lesson covers the architectural pattern used by every major ML platform to prevent data leakage and ensure consistent transformations.

## Learning Objectives
- Understand pipeline architecture and data flow
- Prevent data leakage through proper train/test isolation
- Handle heterogeneous data with ColumnTransformer
- Implement production-ready preprocessing chains
- Serialize pipelines for deployment

## Quick Start

### Setup
```bash
chmod +x setup.sh
./setup.sh
source venv/bin/activate
```

### Run Main Implementation
```bash
python lesson_code.py
```

Expected output:
- Basic pipeline construction and evaluation
- Data leakage prevention demonstration
- ColumnTransformer with mixed data types
- Cross-validation with proper fold isolation
- Pipeline serialization and loading
- Production pipeline pattern

### Run Tests
```bash
pytest test_lesson.py -v
```

Expected: 20+ tests passing covering:
- Pipeline creation and operations
- Data leakage prevention
- ColumnTransformer functionality
- Cross-validation integration
- Serialization/deserialization
- Production patterns

## Key Concepts

### Pipeline Architecture
```
Raw Data â†’ [Transformer 1] â†’ [Transformer 2] â†’ ... â†’ [Estimator] â†’ Predictions
            fit_transform()    fit_transform()        fit()
            transform()        transform()            predict()
```

### Data Flow
- **Training**: Each transformer fits on data, then transforms it for next step
- **Inference**: Each transformer uses fitted parameters to transform, no refitting

### Why Pipelines Matter
1. **Prevent Data Leakage**: Transformers fit only on training data
2. **Reproducibility**: Entire workflow serializes as single object
3. **Maintainability**: Swap components without changing interface
4. **Production Ready**: Direct path from research to deployment

## Production Examples

### Spotify's Recommendation Pipeline
```
User History â†’ Session Filtering â†’ Recency Weighting â†’ 
Genre Encoding â†’ Normalization â†’ Collaborative Filtering â†’ 
Content Scoring â†’ Diversity Reranking â†’ Final Model
```

### Stripe's Fraud Detection Pipeline
```
Transaction â†’ Merchant Encoding â†’ Velocity Features â†’ 
Geographic Risk â†’ Device Fingerprinting â†’ Ensemble Models
```

## File Structure
```
.
â”œâ”€â”€ setup.sh                 # Environment setup
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ lesson_code.py          # Complete pipeline implementations
â”œâ”€â”€ test_lesson.py          # Comprehensive test suite
â””â”€â”€ README.md               # This file
```

## Next Steps
Tomorrow (Day 74) we'll build custom transformers for domain-specific feature engineering, extending pipelines with business logic transformations.

## Additional Resources
- Scikit-learn Pipeline docs: https://scikit-learn.org/stable/modules/compose.html
- Production ML Systems: https://developers.google.com/machine-learning/guides/rules-of-ml

---
**Day 73 of 180-Day AI/ML Course**
EOF

echo "âœ… All files generated successfully!"
echo ""
echo "Next steps:"
echo "  1. chmod +x setup.sh && ./setup.sh"
echo "  2. source venv/bin/activate"
echo "  3. python lesson_code.py"
echo "  4. pytest test_lesson.py -v"

