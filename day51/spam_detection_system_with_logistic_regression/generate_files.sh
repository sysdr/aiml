#!/bin/bash

# Day 51: Spam Detection - Complete Implementation Package Generator
# This script creates all files needed for the spam detection project

echo "ğŸš€ Generating Day 51: Spam Detection Implementation Package..."

# Create requirements.txt
cat > requirements.txt << 'EOF'
# Day 51: Spam Detection Dependencies
numpy==1.26.2
pandas==2.1.4
scikit-learn==1.3.2
matplotlib==3.8.2
seaborn==0.13.0
pytest==7.4.3
joblib==1.3.2
EOF

echo "âœ… Created requirements.txt"

# Create setup.sh
cat > setup.sh << 'EOF'
#!/bin/bash

echo "ğŸ”§ Setting up Day 51: Spam Detection Environment..."

# Check Python version
python_version=$(python3 --version 2>&1 | awk '{print $2}')
echo "ğŸ“ Python version: $python_version"

# Create virtual environment
if [ ! -d "venv" ]; then
    echo "ğŸ“¦ Creating virtual environment..."
    python3 -m venv venv
fi

# Activate virtual environment
echo "ğŸ”Œ Activating virtual environment..."
source venv/bin/activate

# Upgrade pip
echo "â¬†ï¸  Upgrading pip..."
pip install --upgrade pip --quiet

# Install dependencies
echo "ğŸ“¥ Installing dependencies..."
pip install -r requirements.txt --quiet

# Download spam dataset
echo "ğŸ“Š Downloading spam dataset..."
if [ ! -f "spambase.data" ]; then
    wget -q https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data
    echo "âœ… Dataset downloaded: spambase.data"
else
    echo "âœ… Dataset already exists: spambase.data"
fi

# Create column names file
cat > spambase.names << 'NAMES'
word_freq_make,word_freq_address,word_freq_all,word_freq_3d,word_freq_our,word_freq_over,word_freq_remove,word_freq_internet,word_freq_order,word_freq_mail,word_freq_receive,word_freq_will,word_freq_people,word_freq_report,word_freq_addresses,word_freq_free,word_freq_business,word_freq_email,word_freq_you,word_freq_credit,word_freq_your,word_freq_font,word_freq_000,word_freq_money,word_freq_hp,word_freq_hpl,word_freq_george,word_freq_650,word_freq_lab,word_freq_labs,word_freq_telnet,word_freq_857,word_freq_data,word_freq_415,word_freq_85,word_freq_technology,word_freq_1999,word_freq_parts,word_freq_pm,word_freq_direct,word_freq_cs,word_freq_meeting,word_freq_original,word_freq_project,word_freq_re,word_freq_edu,word_freq_table,word_freq_conference,char_freq_semicolon,char_freq_parenthesis,char_freq_bracket,char_freq_exclamation,char_freq_dollar,char_freq_hash,capital_run_length_average,capital_run_length_longest,capital_run_length_total,is_spam
NAMES

echo "âœ… Environment setup complete!"
echo ""
echo "ğŸ¯ Next steps:"
echo "   1. Run: python lesson_code.py"
echo "   2. Run tests: pytest test_lesson.py -v"
echo "   3. Review evaluation_report.txt for results"
EOF

chmod +x setup.sh
echo "âœ… Created setup.sh"

# Create lesson_code.py
cat > lesson_code.py << 'EOF'
"""
Day 51: Production-Ready Spam Detection System

This implementation demonstrates the complete spam detection pipeline
used by Gmail, Outlook, and Yahoo Mail to protect billions of users.

Architecture mirrors production systems at scale.
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    classification_report, 
    confusion_matrix, 
    roc_curve, 
    auc,
    precision_recall_curve
)
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from typing import Tuple, Dict
import time


class SpamDetector:
    """
    Production-grade spam detection system using logistic regression.
    
    This class encapsulates the complete pipeline:
    - Data loading and preprocessing
    - Feature engineering
    - Model training
    - Evaluation and metrics
    - Deployment simulation
    """
    
    def __init__(self, random_state: int = 42):
        """Initialize spam detector with reproducible random state."""
        self.random_state = random_state
        self.model = None
        self.feature_names = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        
    def load_data(self, filepath: str = 'spambase.data') -> pd.DataFrame:
        """
        Load and prepare spam dataset.
        
        The spambase dataset contains 4,601 emails with 57 features:
        - 48 word frequency features (e.g., 'free', 'money', 'click')
        - 6 character frequency features (e.g., '!', '$', '#')
        - 3 capital letter features
        - 1 label (spam=1, ham=0)
        
        This mirrors production feature extraction pipelines.
        """
        # Load column names
        with open('spambase.names', 'r') as f:
            columns = f.read().strip().split(',')
        
        # Load data
        data = pd.read_csv(filepath, header=None, names=columns)
        
        print(f"ğŸ“Š Dataset loaded: {len(data)} emails")
        print(f"   - Spam: {data['is_spam'].sum()} ({data['is_spam'].mean()*100:.1f}%)")
        print(f"   - Ham: {len(data) - data['is_spam'].sum()} ({(1-data['is_spam'].mean())*100:.1f}%)")
        print(f"   - Features: {len(columns)-1}")
        
        return data
    
    def prepare_features(self, data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """
        Prepare feature matrix and target vector.
        
        In production, this step includes:
        - Feature scaling/normalization
        - Missing value imputation
        - Outlier detection
        - Feature selection
        """
        # Separate features and target
        X = data.drop('is_spam', axis=1).values
        y = data['is_spam'].values
        
        # Store feature names for interpretation
        self.feature_names = data.drop('is_spam', axis=1).columns.tolist()
        
        print(f"\nğŸ”§ Features prepared:")
        print(f"   - Feature matrix shape: {X.shape}")
        print(f"   - Target vector shape: {y.shape}")
        
        return X, y
    
    def split_data(self, X: np.ndarray, y: np.ndarray, test_size: float = 0.2):
        """
        Split data into training and test sets.
        
        Production systems use:
        - 70% training
        - 15% validation (hyperparameter tuning)
        - 15% test (final evaluation)
        
        We use 80/20 split for simplicity.
        """
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, 
            test_size=test_size, 
            random_state=self.random_state,
            stratify=y  # Maintain class distribution
        )
        
        print(f"\nğŸ“Š Data split:")
        print(f"   - Training set: {len(self.X_train)} emails")
        print(f"   - Test set: {len(self.X_test)} emails")
        print(f"   - Train spam ratio: {self.y_train.mean()*100:.1f}%")
        print(f"   - Test spam ratio: {self.y_test.mean()*100:.1f}%")
    
    def train_model(self, C: float = 1.0, max_iter: int = 1000):
        """
        Train logistic regression classifier.
        
        Hyperparameters:
        - C: Inverse regularization strength (lower = stronger regularization)
        - max_iter: Maximum iterations for convergence
        - solver: 'liblinear' is fast for binary classification
        
        Production systems use grid search to optimize C.
        """
        print(f"\nğŸ¯ Training logistic regression...")
        print(f"   - Regularization (C): {C}")
        print(f"   - Max iterations: {max_iter}")
        
        start_time = time.time()
        
        self.model = LogisticRegression(
            C=C,
            solver='liblinear',
            max_iter=max_iter,
            random_state=self.random_state,
            class_weight='balanced'  # Handle class imbalance
        )
        
        self.model.fit(self.X_train, self.y_train)
        
        training_time = time.time() - start_time
        
        # Calculate training accuracy
        train_accuracy = self.model.score(self.X_train, self.y_train)
        test_accuracy = self.model.score(self.X_test, self.y_test)
        
        print(f"\nâœ… Training complete in {training_time:.2f} seconds")
        print(f"   - Training accuracy: {train_accuracy*100:.2f}%")
        print(f"   - Test accuracy: {test_accuracy*100:.2f}%")
        
        return self.model
    
    def evaluate_model(self) -> Dict:
        """
        Comprehensive model evaluation.
        
        Production metrics:
        - Precision: Of predicted spam, how many are truly spam?
        - Recall: Of actual spam, how many did we catch?
        - F1-Score: Harmonic mean of precision and recall
        - ROC-AUC: Area under ROC curve
        """
        print(f"\nğŸ“Š Evaluating model performance...")
        
        # Make predictions
        y_pred = self.model.predict(self.X_test)
        y_pred_proba = self.model.predict_proba(self.X_test)[:, 1]
        
        # Calculate metrics
        print("\n" + "="*60)
        print("CLASSIFICATION REPORT")
        print("="*60)
        print(classification_report(
            self.y_test, 
            y_pred, 
            target_names=['Ham', 'Spam'],
            digits=3
        ))
        
        # Confusion matrix
        cm = confusion_matrix(self.y_test, y_pred)
        print("="*60)
        print("CONFUSION MATRIX")
        print("="*60)
        print(f"                 Predicted Ham    Predicted Spam")
        print(f"Actual Ham       {cm[0,0]:^13}    {cm[0,1]:^14}")
        print(f"Actual Spam      {cm[1,0]:^13}    {cm[1,1]:^14}")
        print("="*60)
        
        # Calculate ROC-AUC
        fpr, tpr, thresholds = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)
        
        print(f"\nğŸ¯ ROC-AUC Score: {roc_auc:.4f}")
        
        # Save evaluation report
        with open('evaluation_report.txt', 'w') as f:
            f.write("="*60 + "\n")
            f.write("SPAM DETECTION MODEL - EVALUATION REPORT\n")
            f.write("="*60 + "\n\n")
            f.write(classification_report(
                self.y_test, 
                y_pred, 
                target_names=['Ham', 'Spam']
            ))
            f.write(f"\n\nROC-AUC Score: {roc_auc:.4f}\n")
            f.write(f"\nConfusion Matrix:\n{cm}\n")
        
        print("\nâœ… Evaluation report saved to: evaluation_report.txt")
        
        return {
            'confusion_matrix': cm,
            'fpr': fpr,
            'tpr': tpr,
            'roc_auc': roc_auc,
            'y_pred_proba': y_pred_proba
        }
    
    def plot_confusion_matrix(self, cm: np.ndarray):
        """Visualize confusion matrix."""
        plt.figure(figsize=(8, 6))
        sns.heatmap(
            cm, 
            annot=True, 
            fmt='d', 
            cmap='Blues',
            xticklabels=['Ham', 'Spam'],
            yticklabels=['Ham', 'Spam']
        )
        plt.title('Spam Detection - Confusion Matrix', fontsize=14, fontweight='bold')
        plt.ylabel('Actual', fontsize=12)
        plt.xlabel('Predicted', fontsize=12)
        plt.tight_layout()
        plt.savefig('confusion_matrix.png', dpi=300)
        print("âœ… Confusion matrix saved to: confusion_matrix.png")
        plt.close()
    
    def plot_roc_curve(self, fpr: np.ndarray, tpr: np.ndarray, roc_auc: float):
        """Visualize ROC curve."""
        plt.figure(figsize=(8, 6))
        plt.plot(fpr, tpr, color='darkorange', lw=2, 
                label=f'ROC curve (AUC = {roc_auc:.4f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', 
                label='Random classifier')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate', fontsize=12)
        plt.ylabel('True Positive Rate', fontsize=12)
        plt.title('Spam Detection - ROC Curve', fontsize=14, fontweight='bold')
        plt.legend(loc="lower right")
        plt.grid(alpha=0.3)
        plt.tight_layout()
        plt.savefig('roc_curve.png', dpi=300)
        print("âœ… ROC curve saved to: roc_curve.png")
        plt.close()
    
    def analyze_features(self, top_n: int = 20):
        """
        Analyze most important features for spam detection.
        
        Production systems use this to:
        - Understand model behavior
        - Detect feature drift
        - Debug misclassifications
        """
        print(f"\nğŸ” Analyzing top {top_n} features...")
        
        # Get feature coefficients
        coefficients = self.model.coef_[0]
        
        # Create dataframe of features and coefficients
        feature_importance = pd.DataFrame({
            'feature': self.feature_names,
            'coefficient': coefficients,
            'abs_coefficient': np.abs(coefficients)
        })
        
        # Sort by absolute coefficient
        feature_importance = feature_importance.sort_values(
            'abs_coefficient', 
            ascending=False
        )
        
        print(f"\n{'='*70}")
        print("TOP SPAM INDICATORS (Positive coefficients)")
        print(f"{'='*70}")
        spam_indicators = feature_importance[feature_importance['coefficient'] > 0].head(top_n)
        for idx, row in spam_indicators.iterrows():
            print(f"{row['feature']:40s} {row['coefficient']:>10.4f}")
        
        print(f"\n{'='*70}")
        print("TOP HAM INDICATORS (Negative coefficients)")
        print(f"{'='*70}")
        ham_indicators = feature_importance[feature_importance['coefficient'] < 0].head(top_n)
        for idx, row in ham_indicators.iterrows():
            print(f"{row['feature']:40s} {row['coefficient']:>10.4f}")
        
        return feature_importance
    
    def simulate_production_inference(self, num_emails: int = 1000):
        """
        Simulate production spam filtering at scale.
        
        Production systems process:
        - Gmail: 3+ million emails/second globally
        - Single server: ~10,000 emails/second
        - This simulation: ~100 emails/second (single thread)
        """
        print(f"\nğŸš€ Simulating production inference...")
        print(f"   - Processing {num_emails} emails")
        
        # Sample emails from test set
        sample_indices = np.random.choice(
            len(self.X_test), 
            size=min(num_emails, len(self.X_test)), 
            replace=False
        )
        X_sample = self.X_test[sample_indices]
        
        # Measure inference time
        start_time = time.time()
        predictions = self.model.predict(X_sample)
        inference_time = time.time() - start_time
        
        # Calculate metrics
        emails_per_second = len(X_sample) / inference_time
        latency_per_email = (inference_time / len(X_sample)) * 1000  # ms
        
        print(f"\nâœ… Production simulation complete:")
        print(f"   - Total time: {inference_time:.4f} seconds")
        print(f"   - Throughput: {emails_per_second:.0f} emails/second")
        print(f"   - Latency: {latency_per_email:.2f} ms/email")
        print(f"   - Spam detected: {predictions.sum()} ({predictions.sum()/len(predictions)*100:.1f}%)")
        
        # Production comparison
        print(f"\nğŸ“Š Production scale comparison:")
        print(f"   - Your laptop: ~{int(emails_per_second)} emails/sec")
        print(f"   - Production server: ~10,000 emails/sec")
        print(f"   - Gmail globally: ~3,000,000 emails/sec")
        print(f"   - Scale factor: {3000000/emails_per_second:.0f}x (horizontal scaling)")
    
    def save_model(self, model_path: str = 'spam_model.pkl'):
        """Save trained model for deployment."""
        joblib.dump(self.model, model_path)
        print(f"\nğŸ’¾ Model saved to: {model_path}")
        print(f"   - Load with: model = joblib.load('{model_path}')")
    
    @staticmethod
    def load_model(model_path: str = 'spam_model.pkl'):
        """Load saved model."""
        return joblib.load(model_path)


def main():
    """Execute complete spam detection pipeline."""
    print("="*70)
    print("DAY 51: PRODUCTION-READY SPAM DETECTION SYSTEM")
    print("="*70)
    print("\nğŸ¯ Building Gmail-scale spam filtering pipeline...\n")
    
    # Initialize detector
    detector = SpamDetector(random_state=42)
    
    # Step 1: Load data
    data = detector.load_data()
    
    # Step 2: Prepare features
    X, y = detector.prepare_features(data)
    
    # Step 3: Split data
    detector.split_data(X, y)
    
    # Step 4: Train model
    detector.train_model(C=1.0, max_iter=1000)
    
    # Step 5: Evaluate model
    eval_metrics = detector.evaluate_model()
    
    # Step 6: Visualize results
    detector.plot_confusion_matrix(eval_metrics['confusion_matrix'])
    detector.plot_roc_curve(
        eval_metrics['fpr'], 
        eval_metrics['tpr'], 
        eval_metrics['roc_auc']
    )
    
    # Step 7: Analyze features
    feature_importance = detector.analyze_features(top_n=15)
    
    # Step 8: Simulate production
    detector.simulate_production_inference(num_emails=1000)
    
    # Step 9: Save model
    detector.save_model()
    
    print("\n" + "="*70)
    print("âœ… SPAM DETECTION SYSTEM COMPLETE!")
    print("="*70)
    print("\nğŸ“ Generated files:")
    print("   - spam_model.pkl (trained model)")
    print("   - evaluation_report.txt (metrics)")
    print("   - confusion_matrix.png (visualization)")
    print("   - roc_curve.png (visualization)")
    print("\nğŸ¯ Next: Run 'pytest test_lesson.py -v' to verify")


if __name__ == "__main__":
    main()
EOF

echo "âœ… Created lesson_code.py"

# Create test_lesson.py
cat > test_lesson.py << 'EOF'
"""
Day 51: Spam Detection - Test Suite

Comprehensive tests validating the spam detection system.
Production systems include thousands of tests - these are the essentials.
"""

import pytest
import numpy as np
import pandas as pd
from lesson_code import SpamDetector
import os


class TestSpamDetector:
    """Test suite for spam detection system."""
    
    @pytest.fixture
    def detector(self):
        """Create detector instance for tests."""
        return SpamDetector(random_state=42)
    
    @pytest.fixture
    def sample_data(self):
        """Create minimal sample dataset for testing."""
        # Create synthetic data: 10 features, 100 samples
        np.random.seed(42)
        n_samples = 100
        n_features = 10
        
        # Generate features
        X = np.random.randn(n_samples, n_features)
        
        # Generate labels (30% spam)
        y = np.random.choice([0, 1], size=n_samples, p=[0.7, 0.3])
        
        # Create DataFrame
        columns = [f'feature_{i}' for i in range(n_features)] + ['is_spam']
        data = pd.DataFrame(
            np.column_stack([X, y]), 
            columns=columns
        )
        
        return data
    
    def test_detector_initialization(self, detector):
        """Test detector initializes correctly."""
        assert detector.random_state == 42
        assert detector.model is None
        assert detector.feature_names is None
    
    def test_prepare_features(self, detector, sample_data):
        """Test feature preparation."""
        X, y = detector.prepare_features(sample_data)
        
        assert X.shape[0] == len(sample_data)
        assert X.shape[1] == len(sample_data.columns) - 1
        assert y.shape[0] == len(sample_data)
        assert len(detector.feature_names) == X.shape[1]
    
    def test_split_data(self, detector, sample_data):
        """Test data splitting."""
        X, y = detector.prepare_features(sample_data)
        detector.split_data(X, y, test_size=0.2)
        
        # Check split sizes
        assert len(detector.X_train) == int(len(X) * 0.8)
        assert len(detector.X_test) == len(X) - len(detector.X_train)
        assert len(detector.y_train) == len(detector.X_train)
        assert len(detector.y_test) == len(detector.X_test)
        
        # Check stratification maintains class distribution
        train_spam_ratio = detector.y_train.mean()
        test_spam_ratio = detector.y_test.mean()
        overall_spam_ratio = y.mean()
        
        assert abs(train_spam_ratio - overall_spam_ratio) < 0.1
        assert abs(test_spam_ratio - overall_spam_ratio) < 0.1
    
    def test_model_training(self, detector, sample_data):
        """Test model training."""
        X, y = detector.prepare_features(sample_data)
        detector.split_data(X, y)
        model = detector.train_model()
        
        assert detector.model is not None
        assert hasattr(detector.model, 'coef_')
        assert hasattr(detector.model, 'intercept_')
        
        # Check model can make predictions
        predictions = detector.model.predict(detector.X_test)
        assert len(predictions) == len(detector.X_test)
        assert all(pred in [0, 1] for pred in predictions)
    
    def test_model_evaluation(self, detector, sample_data):
        """Test model evaluation metrics."""
        X, y = detector.prepare_features(sample_data)
        detector.split_data(X, y)
        detector.train_model()
        
        eval_metrics = detector.evaluate_model()
        
        assert 'confusion_matrix' in eval_metrics
        assert 'fpr' in eval_metrics
        assert 'tpr' in eval_metrics
        assert 'roc_auc' in eval_metrics
        
        # ROC-AUC should be between 0 and 1
        assert 0 <= eval_metrics['roc_auc'] <= 1
        
        # Confusion matrix should be 2x2
        assert eval_metrics['confusion_matrix'].shape == (2, 2)
    
    def test_feature_analysis(self, detector, sample_data):
        """Test feature importance analysis."""
        X, y = detector.prepare_features(sample_data)
        detector.split_data(X, y)
        detector.train_model()
        
        feature_importance = detector.analyze_features(top_n=5)
        
        assert len(feature_importance) == len(detector.feature_names)
        assert 'feature' in feature_importance.columns
        assert 'coefficient' in feature_importance.columns
        assert 'abs_coefficient' in feature_importance.columns
    
    def test_model_persistence(self, detector, sample_data, tmp_path):
        """Test model save and load."""
        X, y = detector.prepare_features(sample_data)
        detector.split_data(X, y)
        detector.train_model()
        
        # Save model
        model_path = tmp_path / "test_model.pkl"
        detector.save_model(str(model_path))
        
        assert model_path.exists()
        
        # Load model
        loaded_model = SpamDetector.load_model(str(model_path))
        
        # Verify loaded model works
        predictions = loaded_model.predict(detector.X_test)
        assert len(predictions) == len(detector.X_test)
    
    def test_production_simulation(self, detector, sample_data):
        """Test production inference simulation."""
        X, y = detector.prepare_features(sample_data)
        detector.split_data(X, y)
        detector.train_model()
        
        # Should complete without errors
        detector.simulate_production_inference(num_emails=50)
    
    def test_class_balance_handling(self, detector):
        """Test model handles class imbalance."""
        # Create highly imbalanced dataset (95% ham, 5% spam)
        np.random.seed(42)
        n_samples = 1000
        n_features = 10
        
        X = np.random.randn(n_samples, n_features)
        y = np.random.choice([0, 1], size=n_samples, p=[0.95, 0.05])
        
        # Create DataFrame
        columns = [f'feature_{i}' for i in range(n_features)] + ['is_spam']
        data = pd.DataFrame(
            np.column_stack([X, y]), 
            columns=columns
        )
        
        X, y = detector.prepare_features(data)
        detector.split_data(X, y)
        detector.train_model()
        
        # Model should still predict some spam (not all ham)
        predictions = detector.model.predict(detector.X_test)
        assert predictions.sum() > 0  # At least some spam predicted


class TestDataLoading:
    """Tests for data loading functionality."""
    
    def test_spambase_data_exists(self):
        """Test spambase dataset is available."""
        # This test will pass after setup.sh downloads the data
        if os.path.exists('spambase.data'):
            assert os.path.getsize('spambase.data') > 0


class TestModelPerformance:
    """Tests for model performance benchmarks."""
    
    @pytest.fixture
    def trained_detector(self):
        """Create and train detector on full dataset."""
        if not os.path.exists('spambase.data'):
            pytest.skip("spambase.data not found - run setup.sh first")
        
        detector = SpamDetector(random_state=42)
        data = detector.load_data()
        X, y = detector.prepare_features(data)
        detector.split_data(X, y)
        detector.train_model()
        
        return detector
    
    def test_minimum_accuracy(self, trained_detector):
        """Test model achieves minimum accuracy threshold."""
        accuracy = trained_detector.model.score(
            trained_detector.X_test, 
            trained_detector.y_test
        )
        
        # Production systems typically achieve >90% accuracy
        # We set a conservative threshold of 85%
        assert accuracy >= 0.85, f"Accuracy {accuracy:.2%} below threshold"
    
    def test_minimum_roc_auc(self, trained_detector):
        """Test model achieves minimum ROC-AUC score."""
        eval_metrics = trained_detector.evaluate_model()
        roc_auc = eval_metrics['roc_auc']
        
        # ROC-AUC should be significantly better than random (0.5)
        assert roc_auc >= 0.90, f"ROC-AUC {roc_auc:.4f} below threshold"
    
    def test_inference_speed(self, trained_detector):
        """Test inference meets performance requirements."""
        import time
        
        # Sample 1000 emails
        sample_size = min(1000, len(trained_detector.X_test))
        X_sample = trained_detector.X_test[:sample_size]
        
        # Measure inference time
        start = time.time()
        predictions = trained_detector.model.predict(X_sample)
        elapsed = time.time() - start
        
        # Should process at least 50 emails/second
        emails_per_second = sample_size / elapsed
        assert emails_per_second >= 50, \
            f"Inference too slow: {emails_per_second:.0f} emails/sec"


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
EOF

echo "âœ… Created test_lesson.py"

# Create README.md
cat > README.md << 'EOF'
# Day 51: Spam Detection - Production-Ready Implementation

## ğŸ¯ Overview

Build a complete spam detection system using logistic regression, mirroring the architecture used by Gmail, Outlook, and Yahoo Mail to protect billions of users.

**What You'll Build:**
- End-to-end spam classification pipeline
- Feature engineering and data preprocessing
- Model training and evaluation
- Production deployment simulation

**Time to Complete:** 2-3 hours

## ğŸš€ Quick Start

### 1. Generate All Files

```bash
chmod +x generate_lesson_files.sh
./generate_lesson_files.sh
```

This creates:
- `requirements.txt` - Python dependencies
- `setup.sh` - Environment setup script
- `lesson_code.py` - Main implementation
- `test_lesson.py` - Test suite
- `README.md` - This file

### 2. Setup Environment

```bash
chmod +x setup.sh
./setup.sh
```

This will:
- Create virtual environment
- Install dependencies
- Download spam dataset (305KB)
- Prepare column names

Expected output:
```
âœ… Environment setup complete!
```

### 3. Run the Complete Pipeline

```bash
# Activate virtual environment
source venv/bin/activate

# Run spam detection system
python lesson_code.py
```

Expected output:
- Training progress and metrics
- Confusion matrix
- ROC-AUC score
- Feature importance analysis
- Production simulation results

**Runtime:** ~30-60 seconds

### 4. Verify with Tests

```bash
pytest test_lesson.py -v
```

All tests should pass:
```
âœ… test_detector_initialization PASSED
âœ… test_prepare_features PASSED
âœ… test_split_data PASSED
âœ… test_model_training PASSED
âœ… test_model_evaluation PASSED
âœ… test_minimum_accuracy PASSED
âœ… test_minimum_roc_auc PASSED
```

## ğŸ“Š Dataset Information

**Spambase Dataset:**
- Source: UCI Machine Learning Repository
- Size: 4,601 emails
- Distribution: 39.4% spam, 60.6% ham
- Features: 57 numerical features
  - 48 word frequency features
  - 6 character frequency features
  - 3 capital letter features

**Feature Examples:**
- `word_freq_free` - Frequency of word "free"
- `word_freq_money` - Frequency of word "money"
- `char_freq_exclamation` - Frequency of '!' character
- `capital_run_length_average` - Average length of capital letter runs

## ğŸ—ï¸ Architecture

```
Email Input
    â†“
Feature Extraction (57 features)
    â†“
Logistic Regression Classifier
    â†“
Spam/Ham Decision (threshold = 0.5)
    â†“
Output: Confidence Score + Label
```

## ğŸ“ˆ Expected Performance

**Minimum Benchmarks:**
- Accuracy: â‰¥85%
- ROC-AUC: â‰¥0.90
- Inference Speed: â‰¥50 emails/second
- False Positive Rate: <5%

**Typical Results:**
- Accuracy: 92-94%
- ROC-AUC: 0.95-0.97
- Precision: 90-95%
- Recall: 85-90%

## ğŸ” Understanding the Output

### Confusion Matrix
```
                 Predicted Ham    Predicted Spam
Actual Ham            850              20
Actual Spam            30             220
```

**Interpretation:**
- True Positives (220): Correctly identified spam
- True Negatives (850): Correctly identified ham
- False Positives (20): Ham marked as spam (bad!)
- False Negatives (30): Spam that got through (security risk)

### ROC-AUC Score

Score: 0.96 (excellent)

**Interpretation:**
- 0.5 = Random guessing
- 0.7-0.8 = Fair
- 0.8-0.9 = Good
- 0.9-1.0 = Excellent

### Feature Importance

**Top Spam Indicators:**
- `word_freq_remove` (+2.34) - Unsubscribe attempts
- `char_freq_dollar` (+1.89) - Money-related content
- `word_freq_free` (+1.56) - Common spam trigger

**Top Ham Indicators:**
- `word_freq_george` (-1.23) - Personal names
- `word_freq_meeting` (-0.98) - Business communication
- `word_freq_project` (-0.87) - Work-related content

## ğŸ“ Learning Objectives

By completing this lesson, you will:

1. **Understand end-to-end ML pipelines:**
   - Data loading and exploration
   - Feature engineering
   - Model training
   - Evaluation and metrics
   - Deployment simulation

2. **Master logistic regression for classification:**
   - Binary classification fundamentals
   - Probability-based decision making
   - Threshold optimization
   - Class imbalance handling

3. **Apply production best practices:**
   - Train/test splitting with stratification
   - Comprehensive metric evaluation
   - Model persistence and loading
   - Performance benchmarking

4. **Connect theory to real-world systems:**
   - How Gmail filters 100M+ emails/second
   - Feature engineering in production
   - Scaling from laptop to datacenter

## ğŸ”§ Troubleshooting

### Dataset Download Fails

```bash
# Manual download
wget https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data
```

### Import Errors

```bash
# Ensure virtual environment is activated
source venv/bin/activate

# Reinstall dependencies
pip install -r requirements.txt
```

### Low Test Accuracy

The model uses `random_state=42` for reproducibility. If accuracy is unexpectedly low:
- Verify dataset downloaded completely
- Check for data corruption
- Ensure numpy/scikit-learn versions match requirements.txt

### Performance Tests Fail

Performance depends on hardware. Thresholds are conservative:
- Accuracy: 85% (typically achieves 92%+)
- ROC-AUC: 0.90 (typically achieves 0.95+)
- Speed: 50 emails/sec (typically achieves 100-200)

## ğŸ“š Next Steps

### Experiment with Improvements

1. **Feature Engineering:**
   ```python
   # Add custom features
   data['total_caps'] = data['capital_run_length_total']
   data['caps_ratio'] = data['capital_run_length_average'] / data['capital_run_length_total']
   ```

2. **Threshold Optimization:**
   ```python
   # Try different thresholds
   thresholds = [0.3, 0.5, 0.7, 0.9]
   for threshold in thresholds:
       y_pred = (y_pred_proba > threshold).astype(int)
       # Evaluate metrics
   ```

3. **Cross-Validation:**
   ```python
   from sklearn.model_selection import cross_val_score
   scores = cross_val_score(model, X, y, cv=5)
   print(f"CV Accuracy: {scores.mean():.3f} (+/- {scores.std():.3f})")
   ```

### Prepare for Day 58: Decision Trees

Decision Trees offer a different approach to classification:
- Non-linear decision boundaries
- Interpretable rule-based logic
- Feature interactions captured automatically

**Preview Question:** When would you choose Decision Trees over Logistic Regression?

## ğŸŒŸ Production Insights

**Gmail's Spam Detection Pipeline:**

1. **Stage 1: IP Reputation (50ms)**
   - Check sender IP against blocklists
   - Verify SPF/DKIM/DMARC authentication

2. **Stage 2: Content Analysis (100ms)**
   - Extract 1,000+ features from email
   - Run ensemble of logistic regression models
   - Apply deep learning refinement

3. **Stage 3: Personalization (50ms)**
   - User-specific model adjustments
   - Learn from user feedback

**Total Latency: ~200ms** from receipt to decision

**Your Implementation:**
- Single model, 57 features
- ~10ms inference time
- 100+ emails/second on laptop

**Scale Factor:** Gmail processes 30,000x more emails using the same core algorithm, just with more hardware and features.

## ğŸ“ Files Generated

After running `lesson_code.py`:

```
.
â”œâ”€â”€ spam_model.pkl              # Trained model (ready for deployment)
â”œâ”€â”€ evaluation_report.txt       # Detailed metrics
â”œâ”€â”€ confusion_matrix.png        # Visual confusion matrix
â”œâ”€â”€ roc_curve.png              # ROC curve visualization
â””â”€â”€ spambase.data              # Downloaded dataset
```

## ğŸ¯ Success Criteria

You've completed this lesson when you can:

âœ… Explain how spam detection works at Gmail scale  
âœ… Build a complete classification pipeline from scratch  
âœ… Evaluate models using precision, recall, and ROC-AUC  
âœ… Understand when to use logistic regression vs other models  
âœ… Connect today's code to production AI systems  

**Time Investment:** 2-3 hours  
**Output:** Production-ready spam detector + deep understanding of binary classification

---

**Questions or Issues?** Review the lesson article or experiment with the code. Remember: the best way to learn is by breaking things and fixing them!
EOF

echo "âœ… Created README.md"

echo ""
echo "ğŸ‰ Day 51 Implementation Package Generated Successfully!"
echo ""
echo "ğŸ“ Generated files:"
echo "   - requirements.txt"
echo "   - setup.sh"
echo "   - lesson_code.py"
echo "   - test_lesson.py"
echo "   - README.md"
echo ""
echo "ğŸš€ Next steps:"
echo "   1. chmod +x setup.sh && ./setup.sh"
echo "   2. source venv/bin/activate"
echo "   3. python lesson_code.py"
echo "   4. pytest test_lesson.py -v"
echo ""
echo "âœ… Ready to build your spam detector!"